\documentclass[xcolor=pdftex,dvipsnames,table,mathserif]{beamer}
\input{../../setting.tex}
\usepackage{physics}

\graphicspath{{../graphics/}}

\AtBeginSection[]{
  \begin{frame}{Contents}
  \tableofcontents[currentsection, hideothersubsections]
  \end{frame}
}

\AtBeginSubsection[]{
  \begin{frame}{Contents}
  \tableofcontents[currentsection, subsectionstyle=show/shaded/hide]
  \end{frame}
}

\setbeamertemplate{footline}[frame number]{}
\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{section in toc}[square]
\setbeamertemplate{items}[square]

\title{Convolutional neural networks}
\author{E. Decencière}
\date{MINES ParisTech\\
  PSL Research University\\
  Center for Mathematical Morphology
}
\titlegraphic{\includegraphics[height=1.7cm]{../graphics/logoemp}}

\useinnertheme{rounded}
\usecolortheme{rose}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\begin{frame}
\titlepage
\end{frame}

\frame{
\frametitle{Contents}
\tableofcontents[hidesubsections]
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{A picture is worth a thousand words}

  \begin{columns}
    \begin{column}{.5\textwidth}
      \begin{block}{Definition}
        \begin{itemize}
        \item Classically, an image is a matrix of values belonging to $[0, \ldots, 255]$ (grey level images) or to $[0, \ldots, 255]^3$ (color images).
        \item More generally, an image is a $q$-dimensional array of values belonging to $R^d$.
        \end{itemize}
      \end{block}

    \end{column}

    \begin{column}{.5\textwidth}
      \begin{figure}
        \centering
        \includegraphics[width=4cm]{../graphics/faune.png}
        \caption{Grey level values around the left eye of the faun.}
      \end{figure}

    \end{column}
  \end{columns}

  \begin{alertblock}{}
   Designing computer vision systems that are able to extract semantic information from an image is a difficult task. How can we build systems that extract meaning from an image?
  \end{alertblock}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Extracting semantic information from an image}

\begin{columns}
  \begin{column}{.5\textwidth}
\begin{itemize}
\item Where is the phone? (localization task)
\item How many mugs are there? (quantification task)
\item Is there a window in the room?
\item At what time of the day was the photograph taken?
\end{itemize}
  \end{column}

  \begin{column}{.5\textwidth}
    \begin{figure}[ht]
      \centering
      \includegraphics[height=8cm]{bureau-1}
    \end{figure}

  \end{column}
\end{columns}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frame{
\frametitle{Applying machine learning to images}

\begin{columns}
  \begin{column}{.5\textwidth}
    \begin{block}{Classical approach}
      \begin{itemize}
      \item Compute features from the image
      \item Apply machine learning to those features
      \end{itemize}
    \end{block}

  \end{column}

  \begin{column}{.5\textwidth}
    \begin{block}{Modern neural networks approach}
      \begin{itemize}
      \item Directly take as input the image pixels
      \item The network is supposed to build its own features
      \end{itemize}
    \end{block}

  \end{column}
\end{columns}


}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{
  \frametitle{Some accomplishments}

  \begin{block}{ImageNet Large Scale Visual Recognition Challenge (ILSVRC)}
    2012: \emph{AlexNet} \cite{krizhevsky_imagenet_2012} won this challenge by a large margin
    \end{block}

  The database contains more that 1 million training images, belonging to 1000 different classes (including 120 dog breeds!).


  }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{
  \frametitle{Some accomplishments (cont.)}

\begin{itemize}
\item 2011: first super-human performance, IJCNN 2011 traffic sign recognition contest \cite{ciresan_committee_2011}
\item 2012: visual object detection (Mitosis detection in breast cancer histology \cite{ciresan_mitosis_2013})
\item 2012: segmentation competition (neuronal membranes in electron microscopy images \cite{ciresan_deep_2012})
\item 2016: AlphaGo beats Lee Sedol, one of the best go players, in a 5-game match
\end{itemize}

  }


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{
\frametitle{Convolutional neural networks in deep learning}

\begin{itemize}

%% \item They play a major role in deep learning
\item They are pivotal to many of the successes achieved by neural networks these recent years
\item They are interesting for dealing with regular structured data, such as images (or board games!)

\end{itemize}

\begin{block}{}
  Two acronyms are used for convolutional neural networks in the literature: \emph{CNN} and \emph{ConvNet}.
  \end{block}

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Application of fully-connected networks to image classification}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{From neural layers to convolutional layers}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{
\frametitle{Most common artificial neuron}

\begin{figure}
\includegraphics[height=3cm]{neurone}
\end{figure}

\begin{itemize}

\item $b, w_1, \ldots, w_n$ are the neuron parameters, to be learnt

\item $\alpha$ is the activation or transfer function

\end{itemize}


}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{
\frametitle{Neural network}


\begin{figure}
  \includegraphics[height=5cm]{network}
\end{figure}

{\small(from http://www.jtoy.net)}

}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{
\frametitle{Dealing with images}

Fully connected layers:

\begin{itemize}

\item scale badly to large size images

\item do not take into account the local structure of images

\end{itemize}


}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{
\frametitle{Input image, input neurons}

In the scalar case, each input pixel is considered as an input neuron.

\vspace{10pt}

\begin{columns}

  \begin{column}<1->{0.45\textwidth}
    \begin{center}
      \includegraphics[width=0.50\textwidth]{image_as_pixels.png}
    \end{center}
  \end{column}

  \begin{column}<2->{0.45\textwidth}
    \begin{center}
      \includegraphics[width=0.50\textwidth]{image_as_neurons.png}

    \end{center}
  \end{column}

\end{columns}

\vspace{10pt}

\begin{block}{}
In the following slides, for illustration purposes, we will consider one-dimensional images
\end{block}

}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frame{
\frametitle{Towards convolutional layers}


\begin{columns}

  \begin{column}<1->{0.3\textwidth}
    \begin{center}
      \includegraphics[width=0.74\textwidth]{fully_connected_layer.png}
      \\Fully connected layer: $n(s+1)$ weights
    \end{center}
  \end{column}

  \begin{column}<2->{0.3\textwidth}
    \begin{center}
      \includegraphics[width=0.74\textwidth]{locally_connected_layer.png}
      \\Locally conn. layer: $n(s+1)$ weights
    \end{center}
  \end{column}

  \begin{column}<3->{0.3\textwidth}
    \begin{center}
      \includegraphics[width=0.74\textwidth]{convolutional_layer.png}
      \\Weight replication: $s+1$ weights
    \end{center}
  \end{column}

\end{columns}

\begin{block}<4->{}
  A convolutional layer computes a convolution, plus a constant, of the precedent layer.
\end{block}


}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frame{
\frametitle{Stride}

A convolutional layer can at the same time downsample the image by applying a sampling step, or \emph{stride}.

\begin{columns}

  \begin{column}<1->{0.3\textwidth}
    \begin{center}
      \includegraphics[width=0.60\textwidth]{stride1.png}
      \\Stride 1
    \end{center}
  \end{column}

  \begin{column}<2->{0.3\textwidth}
    \begin{center}
      \includegraphics[width=0.60\textwidth]{stride2.png}
      \\Stride 2
    \end{center}
  \end{column}

  \begin{column}<3>{0.3\textwidth}
    \begin{center}
      \includegraphics[width=0.60\textwidth]{stride3.png}
      \\Stride 3
    \end{center}
  \end{column}

\end{columns}

\begin{block}{}
  Note that today, for reducing the layers size, max pooling layers are often preferred.
  \end{block}


}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frame{
\frametitle{Several filters in the same convolutional layer}

    \begin{center}
      \includegraphics[width=0.53\textwidth]{convolutional_layer2.png}

    \end{center}


}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frame{
\frametitle{Several filters in the same convolutional layer}

    \begin{center}
      \includegraphics[width=0.53\textwidth]{convolutional_layer3.png}

    \end{center}


}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frame{
\frametitle{Several filters in the same convolutional layer}

    \begin{center}
      \includegraphics[width=0.53\textwidth]{convolutional_layer4.png}

    \end{center}


}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frame{
\frametitle{Consequences on the parameter number}

\begin{center}
  \includegraphics[width=0.5\textwidth]{convolutional_layer4.png}
\end{center}

\begin{itemize}
\item<1-> How many parameters do we have in layer 1?
\item<2-> $d^1 \times (s + 1)$
\item<3-> In layer 2?
\item<4-> $d^2 \times (d^1 \times s + 1)$
\end{itemize}

}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frame{
\frametitle{Multi-valued images}


An input image with $p$ channels (for instance à colour image with 3 channels) can be represented by an input layer of depth 3

\begin{center}
  \includegraphics[width=0.31\textwidth]{input_vector_image.png}
\end{center}



}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frame{
\frametitle{Some properties}

\begin{itemize}
  \item Translation invariance
  \item Efficient implementation using matrix operations and graphical processing units
\end{itemize}

}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Building convolutional networks}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{
\frametitle{Max pooling}

\begin{itemize}
\item Convolutional networks often contain subsampling steps. These can be done using strides of 2 or more within convolutional layers or, as it is common practice today, using \emph{max pooling} layers.

\item Sampling is only applied along the spatial dimensions, not along the dimension of the filters.

  \end{itemize}

\begin{center}
  \includegraphics[width=0.41\textwidth]{max_pooling.png}
\end{center}


}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{
\frametitle{Main components of a convolutional neural network}

Many successful architectures, especially for image classification, follow the same pattern:

\begin{enumerate}
\item Several iterations of: One or several convolutional layers, with increasing depth, followed by max pooling
\item A few fully connected layers
\end{enumerate}

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{
\frametitle{Example networks: fovea detection}

  \begin{center}
  \includegraphics[width=\textwidth]{fovea_convnet2.png}
\end{center}

  }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% \frame{
%% \frametitle{A typical convolutional architecture for image classification}

%% \begin{figure}
%%   \includegraphics[width=9.5cm]{conv_net_classif}
%%   \caption{Architecture used for the classification of the NORB dataset (from \cite{scherer_evaluation_2010})}
%% \end{figure}

%% Note that layer P4 can be seen as made of features, which are then classified by the two fully connected layers.


%% }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{
  \frametitle{Example: VGGnet}


  \begin{itemize}
  \item Proposed by K. Simonyan and A. Zisserman from the University of Oxford \cite{simonyan_very_2014}

  \item Number of parameters (VGG16): $138$ million.

   \end{itemize}

  \begin{center}
    \begin{figure}
    \includegraphics[width=0.5\textwidth]{vgg16.png}
    \caption{VGG16 (From https://www.cs.toronto.edu/~frossard/post/vgg16/)}
    \end{figure}
\end{center}


}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{
  \frametitle{Example: GoogLeNet}


  \begin{itemize}

  \item This network won the ImageNet Large Scale Visual Recognition Competition (ILSVRC) in 2014.

  \item Number of parameters: \emph{only} $~5$ million.

   \end{itemize}

  \begin{center}
  \includegraphics[width=\textwidth]{googlenet.png}
\end{center}

  ResNet won the following year. One of its versions contains more than 1000 layers.

}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{
\frametitle{Current trends}

\begin{itemize}
\item Small convolutions ($3\times3$)
\item Increasing number of layers - more than 1000
\item Skip connections
\end{itemize}

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Practical considerations}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{
\frametitle{Designing a convolutional neural network}

\begin{itemize}
\item Network architecture
\item Hyper-parameter setting
\item Optimization method and parameters
\end{itemize}


\begin{block}{}
  Learning, specially for complex networks, can be difficult. It is always time consuming.
  \end{block}

}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{
\frametitle{Using an existing network}

\begin{itemize}
\item Replicate network architecture and hyper-parameters
\item Load weights
\end{itemize}

\begin{block}{}
  With standard libraries this is very simple. Prediction time is usually fast.
  \end{block}


}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{
\frametitle{ConvNets can be fooled}


Deep learning can produce astonishing results \cite{nguyen_deep_2015}...
\begin{figure}
  \includegraphics[width=0.8\textwidth]{dl_easily_fooled.png}
\end{figure}


}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{
\frametitle{Main deep learning libraries}

Deep learning is a very competitive domain, where code sharing is very common.

\begin{itemize}
\item Theano
\item Torch
\item Tensorflow
\item Caffe
\item MatConvNet
\end{itemize}

\begin{block}{Keras}
  Keras is a very easy to use interface to Theano and Tensorflow.
\\
  See demonstration.
  \end{block}


}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Visualization}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{
  \frametitle{Visualizing at least what we don't understand}

  We do not fully understand today where the good performances of deep learning come from. But we can at least have a look at what is going on inside the networks.

  \begin{itemize}
  \item Neuron outputs (activations)
  \item Filter values
  \item ``Important'' pixels
    \end{itemize}


}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{
  \frametitle{Maximal neuron activation}

Which images maximally activate a given neuron? \cite{girshick_rich_2014}

\begin{figure}
  \includegraphics[width=\textwidth]{max_act_images.jpeg}
\end{figure}


  }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frame{
\frametitle{Limitations}

For a deep-learning solution to work, you need:

\begin{itemize}

\item A lot of annotated data
\item A lot of fiddling (different architectures; hyper-parameters)
\item One (or, even better, several) powerful GPUs

\end{itemize}

Moreover, these models lack interpretability, and fitting them can be very time-consuming.


}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frame{
\frametitle{Some missing topics}

\begin{itemize}
\item Transfer learning / domain adaptation
\item Data augmentation
\item Generative adversarial networks (GANs)
\item Optimization, gradient descent, regularization
\item ...
\end{itemize}

(These are not specific to ConvNets)

}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frame{
\frametitle{Some useful pointers}

\begin{itemize}
  \item Course by G. Hinton on neural networks (coursera, youtube)
\item Stanford course on convolutional neural networks: http://cs231n.github.io/
\item Hardware recommendations: https://timdettmers.wordpress.com/2014/08/14/which-gpu-for-deep-learning/
\end{itemize}

}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Conclusion}



\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{References}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame[allowframebreaks]{

\scriptsize

\frametitle{References}

%\bibliographystyle{amsalpha}
%\bibliographystyle{apalike}

\bibliography{edf.bib}

\normalsize

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
